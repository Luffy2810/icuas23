# ICUAS 2023 UAV Competition Solution

![ROS](https://img.shields.io/badge/ROS-Noetic-blue)
![Python](https://img.shields.io/badge/Python-3.8-brightgreen)
![CUDA](https://img.shields.io/badge/CUDA-11.6-green)
![License](https://img.shields.io/badge/License-GPL--3.0-red)

An autonomous UAV solution for the **ICUAS 2023 International Competition**, featuring real-time crack detection, tile classification, and intelligent exploration using a combination of **EGO-Planner** for trajectory planning, **YOLOv7** for object detection, and **ORB-SLAM2** for visual SLAM.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Key Features](#key-features)
- [Repository Structure](#repository-structure)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Components](#components)
  - [EGO-Planner](#ego-planner)
  - [YOLOv7 Detection](#yolov7-detection)
  - [ORB-SLAM2 Integration](#orb-slam2-integration)
  - [Trajectory Controller](#trajectory-controller)
- [Configuration](#configuration)
- [Usage](#usage)
- [Troubleshooting](#troubleshooting)
- [Citation](#citation)
- [License](#license)

---

## Overview

This repository contains our solution for the ICUAS 2023 UAV Competition, where the objective is to autonomously navigate a UAV through an arena to locate and classify textured tiles (detecting cracks vs. non-cracks). The solution integrates:

- **Autonomous Exploration**: Intelligent navigation to Points of Interest (POIs)
- **Real-time Detection**: YOLOv7-based tile detection with a secondary classification network
- **Trajectory Planning**: EGO-Planner for ESDF-free gradient-based local planning
- **Visual SLAM**: ORB-SLAM2 for pose estimation and localization
- **Depth Processing**: RGB-D alignment and depth-to-3D coordinate transformation

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ICUAS23 Solution Pipeline                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Gazebo     â”‚â”€â”€â”€â–¶â”‚  ArduPilot SITL  â”‚â”€â”€â”€â–¶â”‚   MAVROS        â”‚                â”‚
â”‚  â”‚  Simulator  â”‚    â”‚  (ArduCopter)    â”‚    â”‚   Interface     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                       â”‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         ROS Communication Layer                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                    â”‚                    â”‚                    â”‚        â”‚
â”‚         â–¼                    â–¼                    â–¼                    â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ POI Handler â”‚    â”‚  EGO-Planner â”‚    â”‚   YOLOv7    â”‚    â”‚  ORB-SLAM2   â”‚   â”‚
â”‚  â”‚ & Explorer  â”‚    â”‚  Trajectory  â”‚    â”‚  Detection  â”‚    â”‚  Localizationâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                  â”‚                    â”‚                              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´                              â”‚
â”‚                            â”‚                                                    â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚
â”‚                   â”‚  Trajectory     â”‚                                          â”‚
â”‚                   â”‚  Controller     â”‚                                          â”‚
â”‚                   â”‚  (traj_node.py) â”‚                                          â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Features

| Feature | Description |
|---------|-------------|
| ğŸ¯ **Intelligent POI Exploration** | Distance-sorted POI traversal with adaptive height scanning |
| ğŸ” **Dual-Stage Detection** | YOLOv7 tile detection + CNN-based crack classification |
| ğŸ›« **ESDF-Free Planning** | EGO-Planner for ~1ms trajectory computation |
| ğŸ“· **RGB-D Processing** | Depth-to-RGB alignment with 3D coordinate estimation |
| ğŸ® **PD Yaw Control** | Smooth yaw trajectory generation with PD controller |
| ğŸ”„ **Auto Return-to-Home** | Automatic return to takeoff point before timeout |
| ğŸ³ **Docker Support** | Full containerized deployment with NVIDIA GPU support |

---

## Repository Structure

```
icuas23/
â”œâ”€â”€ docker/                          # Docker configuration and launch scripts
â”‚   â”œâ”€â”€ Dockerfile                   # Main container definition (CUDA 11.6 + ROS)
â”‚   â”œâ”€â”€ build.sh                     # Build script for Docker image
â”‚   â”œâ”€â”€ icuas.sh                     # Container orchestration and GPU passthrough
â”‚   â””â”€â”€ readme.md                    # Docker usage instructions
â”‚
â”œâ”€â”€ ego-planner/                     # ESDF-free gradient-based local planner
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ ego_planner/             # Core planner package
â”‚   â”‚   â”œâ”€â”€ plan_env/                # Planning environment representation
â”‚   â”‚   â”œâ”€â”€ traj_utils/              # Trajectory utilities and TOPP-RA
â”‚   â”‚   â””â”€â”€ uav_simulator/           # Lightweight quadrotor simulator
â”‚   â””â”€â”€ README.md                    # EGO-Planner documentation
â”‚
â”œâ”€â”€ icuas23_competition/             # Competition-specific ROS package
â”‚   â”œâ”€â”€ launch/                      # ROS launch files
â”‚   â”œâ”€â”€ models/                      # Gazebo world models
â”‚   â”œâ”€â”€ startup/challenge/           # Challenge startup configuration
â”‚   â”‚   â”œâ”€â”€ session.yml              # TMux session definition
â”‚   â”‚   â”œâ”€â”€ traj_node.py             # Main trajectory controller node
â”‚   â”‚   â”œâ”€â”€ spawn_tiles.py           # Dynamic tile spawning
â”‚   â”‚   â””â”€â”€ custom_config/           # PID and TOPP configuration
â”‚   â”œâ”€â”€ worlds/                      # Gazebo world definitions
â”‚   â””â”€â”€ README.md                    # Competition package documentation
â”‚
â”œâ”€â”€ orb_ws/                          # ORB-SLAM2 ROS workspace
â”‚   â””â”€â”€ src/orb_slam_2_ros/          # ORB-SLAM2 ROS wrapper
â”‚       â”œâ”€â”€ orb_slam2/               # Core ORB-SLAM2 library
â”‚       â”œâ”€â”€ ros/                     # ROS interface nodes
â”‚       â””â”€â”€ docker/                  # ORB-SLAM specific Docker files
â”‚
â”œâ”€â”€ orb_utils/                       # SLAM utilities and post-processing
â”‚   â”œâ”€â”€ d2r.py                       # Depth-to-RGB alignment node
â”‚   â”œâ”€â”€ broadcast.py                 # TF broadcaster utilities
â”‚   â”œâ”€â”€ plotter.py                   # Trajectory visualization
â”‚   â”œâ”€â”€ rmse.py                      # RMSE calculation for evaluation
â”‚   â””â”€â”€ icuas/                       # ICUAS-specific SLAM scripts
â”‚       â”œâ”€â”€ icuas_FBM1.sh            # TMux automation for rosbag processing
â”‚       â””â”€â”€ readme.txt               # SLAM pipeline documentation
â”‚
â”œâ”€â”€ yolov7/                          # YOLOv7 object detection
â”‚   â”œâ”€â”€ detect_class.py              # Detection + classification wrapper
â”‚   â”œâ”€â”€ models/                      # Network architecture definitions
â”‚   â”œâ”€â”€ utils/                       # Detection utilities
â”‚   â”œâ”€â”€ cfg/                         # Model configurations
â”‚   â””â”€â”€ readme.md                    # Weight file download instructions
â”‚
â””â”€â”€ README.md                        # This file
```

---

## Prerequisites

### Hardware Requirements
- **GPU**: NVIDIA GPU with CUDA 11.6+ support (Compute Capability 6.1+)
- **RAM**: Minimum 16GB recommended
- **Storage**: ~30GB for Docker image and dependencies

### Software Requirements
- **OS**: Ubuntu 20.04 LTS (Focal Fossa)
- **Docker**: 20.10+ with NVIDIA Container Toolkit
- **ROS**: Noetic Ninjemys (installed inside Docker)
- **CUDA**: 11.6+ with cuDNN 8

---

## Installation

### Option 1: Docker (Recommended)

1. **Install Docker with NVIDIA support**:
   ```bash
   curl https://raw.githubusercontent.com/larics/uav_ros_simulation/main/installation/dependencies/docker.sh | bash
   ```

2. **Clone the repository**:
   ```bash
   git clone <repository-url> icuas23
   cd icuas23
   ```

3. **Build the Docker image**:
   ```bash
   cd docker
   chmod +x build.sh
   ./build.sh
   ```

4. **Start the Docker container**:
   ```bash
   chmod +x icuas.sh
   ./icuas.sh
   ```

### Option 2: Native Installation

1. **Install UAV ROS Simulation stack**:
   ```bash
   git clone https://github.com/larics/uav_ros_simulation.git
   ./uav_ros_simulation/installation/install_and_setup_workspace.sh uav_ws
   ```

2. **Install additional dependencies**:
   ```bash
   sudo apt-get install libarmadillo-dev ffmpeg libsm6 libxext6
   pip install torch torchvision gdown
   ```

3. **Build all packages**:
   ```bash
   cd ~/uav_ws
   catkin build
   ```

---

## Quick Start

### Inside Docker Container

```bash
# 1. Start the Docker container (from host)
cd docker
./icuas.sh

# 2. Inside the container - build exploration files
cd /root/
./run.sh

# 3. Navigate to challenge directory
roscd icuas23_competition/startup/challenge

# 4. Start the simulation
./start.sh
```

### What happens when you run `start.sh`:

1. **ROS Core** initializes
2. **ArduPilot SITL** starts with simulated ArduCopter
3. **Gazebo** launches with the competition world
4. **Tiles spawn** at randomized positions around POIs
5. **UAV arms and takes off** automatically
6. **EGO-Planner** provides trajectory planning
7. **YOLOv7** begins real-time tile detection
8. **traj_node.py** orchestrates exploration and classification

---

## Components

### EGO-Planner

A lightweight gradient-based local planner that eliminates ESDF construction for faster computation (~1ms planning time).

**Key parameters** (in `ego_planner/launch/run_in_sim.launch`):
```yaml
max_vel: 2.0          # Maximum velocity (m/s)
max_acc: 3.0          # Maximum acceleration (m/sÂ²)
planning_horizon: 7.5 # Planning horizon distance (m)
```

**Launch independently**:
```bash
# Terminal 1: RViz visualization
roslaunch ego_planner rviz.launch

# Terminal 2: Planner
roslaunch ego_planner run_in_sim.launch
```

### YOLOv7 Detection

Dual-stage detection pipeline:
1. **Stage 1**: YOLOv7 detects tiles in the camera feed
2. **Stage 2**: Classification CNN determines crack vs. non-crack

**Required weight files** (downloaded during Docker build):
```bash
# Detection model
gdown 1rF0Hq7JhosXx8EM1yJu1DXQ6nPctAKtq  # best.pt

# Classification model  
gdown 1k7jzh2hdD4TSVaW5j6WcsRq1OX35xj4P  # classify.pt
```

**Detection class usage**:
```python
from detect_class import mlcv

detector = mlcv()
detections, coords, annotated_img = detector.detect(image)
```

### ORB-SLAM2 Integration

Visual SLAM for localization using RGB-D camera input.

**Run ORB-SLAM2 with rosbag**:
```bash
cd orb_utils/icuas
./icuas_FBM1.sh <bagfile>.bag
```

**Pipeline steps**:
1. Launches `roscore` and `orb_slam3_ros`
2. Plays rosbag for sensor data
3. Saves initial pose from Vicon
4. Exports trajectory in camera frame
5. Transforms to world frame output

### Trajectory Controller

The main control node (`traj_node.py`) handles:

| Function | Description |
|----------|-------------|
| `callback_poi()` | Receives and sorts POIs by distance |
| `detect2()` | Executes vertical scan pattern at POI |
| `Yaw_Traj_Gen()` | Generates smooth yaw trajectories with PD control |
| `delete_poi()` | Removes POIs after successful detection |
| `Return_to_takeoffpt()` | Auto-return before competition timeout |

**ROS Topics**:
```
Published:
  /red/position_hold/trajectory    # Direct trajectory commands
  /red/tracker/input_trajectory    # TOPP-RA trajectory input
  /red/crack_image_annotated       # Annotated detection output

Subscribed:
  /red/poi                         # Points of Interest
  /red/odometry                    # UAV odometry
  /red/camera/color/image_raw      # RGB camera feed
  /red/camera/depth/image_raw      # Depth camera feed
  /planning/pos_cmd                # EGO-Planner position commands
```

---

## Configuration

### Position Control
`startup/challenge/custom_config/position_control_thrust.yaml`:
```yaml
Kp_x: 10.0
Kp_y: 10.0
Kp_z: 8.0
Kd_x: 5.0
Kd_y: 5.0
Kd_z: 4.0
```

### TOPP Trajectory Generation
`startup/challenge/custom_config/topp_config_custom.yaml`:
```yaml
max_velocity: 2.0
max_acceleration: 3.0
sampling_dt: 0.01
```

### Camera Parameters
In `traj_node.py`:
```python
self.focalx = 381.36246688113556
self.focaly = 381.36246688113556
self.cx = 320.5
self.cy = 240.5
```

---

## Usage

### Running the Full Competition

```bash
# Start everything with the session file
roscd icuas23_competition/startup/challenge
./start.sh
```

### Testing Individual Components

**Test EGO-Planner only**:
```bash
roslaunch ego_planner simple_run.launch
```

**Test YOLOv7 detection**:
```python
import cv2
from detect_class import mlcv

detector = mlcv()
img = cv2.imread('test_image.jpg')
detections, coords, result = detector.detect(img)
cv2.imshow('Detection', result)
cv2.waitKey(0)
```

**Test depth alignment**:
```bash
rosrun icuas23_competition d2r.py
```

### Modifying Tile Locations

Edit `spawn_tiles.py` or use the session file to change spawn positions:
```bash
rosrun icuas23_competition spawn_tiles.py __ns:="red"
```

---

## Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| **Docker GPU not detected** | Ensure NVIDIA Container Toolkit is installed: `nvidia-smi` should work inside container |
| **Gazebo crashes on startup** | Increase shared memory: `docker run --shm-size=4gb ...` |
| **YOLOv7 model not loading** | Verify weight files exist in `/root/yolov7/` |
| **EGO-Planner not responding** | Check if `/planning/pos_cmd` topic is publishing |
| **Camera images black** | Wait for Gazebo to fully load textures |

### Updating Packages

```bash
# Update competition package
cd ~/uav_ws/src/icuas23_competition
git pull origin main --rebase
catkin build

# Rebuild Docker image (if needed)
./docker_build.sh --build-args "--no-cache --pull" --focal
```

### Debug Commands

```bash
# Check active topics
rostopic list | grep red

# Monitor trajectory commands
rostopic echo /red/position_hold/trajectory

# View detection output
rosrun rqt_image_view rqt_image_view /red/crack_image_annotated

# Check POI data
rostopic echo /red/poi
```

---

## Citation

If you use this work in your research, please cite:

```bibtex
@article{Markovic2023,
  doi = {10.1007/s10846-023-01909-z},
  url = {https://doi.org/10.1007/s10846-023-01909-z},
  year = {2023},
  month = jul,
  publisher = {Springer Science and Business Media LLC},
  volume = {108},
  number = {3},
  author = {Lovro Markovic and Frano Petric and Antun Ivanovic and 
            Jurica Goricanec and Marko Car and Matko Orsag and Stjepan Bogdan},
  title = {Towards A Standardized Aerial Platform: ICUAS'22 Firefighting Competition},
  journal = {Journal of Intelligent \& Robotic Systems}
}
```

### Related Publications

**EGO-Planner**:
```bibtex
@article{Zhou2020,
  title={EGO-Planner: An ESDF-free Gradient-based Local Planner for Quadrotors},
  author={Zhou, Xin and Wang, Zhepei and Xu, Chao and Gao, Fei},
  journal={IEEE Robotics and Automation Letters},
  year={2020}
}
```

**YOLOv7**:
```bibtex
@article{Wang2022,
  title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2207.02696},
  year={2022}
}
```

---

## License

This project is licensed under the **GPL-3.0 License** - see the [LICENSE](ego-planner/LICENSE) file for details.

### Component Licenses:
- **EGO-Planner**: GPL-3.0
- **YOLOv7**: GPL-3.0  
- **ORB-SLAM2**: GPL-3.0
- **uav_ros_simulation**: BSD-3-Clause

---

## Acknowledgments

- [LARICS Lab](https://github.com/larics) - UAV ROS Simulation framework
- [ZJU-FAST-Lab](https://github.com/ZJU-FAST-Lab) - EGO-Planner
- [WongKinYiu](https://github.com/WongKinYiu/yolov7) - YOLOv7
- [ORB-SLAM2](https://github.com/raulmur/ORB_SLAM2) - Visual SLAM

---

## Contact

For technical questions about this implementation, please open an issue in this repository.

For competition-related inquiries, refer to the [ICUAS 2023 Competition Discussions](https://github.com/larics/icuas23_competition/discussions).
